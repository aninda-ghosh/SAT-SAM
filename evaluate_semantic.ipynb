{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rpn.build_rpn import RPN_Model\n",
    "from sam.build_sam import SAM_Model\n",
    "from transformers import pipeline\n",
    "\n",
    "from data_builder.build_dataset import PlanetscopeDataset\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from eval_utils import filter_boxes_predictions, filter_boxes, calculate_iou, calculate_precision_recall, filter_masks\n",
    "from eval_utils import generate_random_bounding_boxes, generate_uniform_spaced_bounding_boxes\n",
    "\n",
    "import pandas as pd\n",
    "from rpn import _transforms as T\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(image_enhancement=\"FALSE\"):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    if image_enhancement == \"TRUE\":\n",
    "        transforms.append(T.ContrastBasedAdaptiveGammaCorrection())\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and Print the evaluation config from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Configuration\n",
      "{\n",
      " \"DATASET_PATH\": \"/scratch/aghosh57/SAT-SAM(Dataset)/ps_rwanda/all_dataset/\",\n",
      " \"DATASET\": \"RWANDA\",\n",
      " \"MODEL\": \"SAM\",\n",
      " \"IMAGE_ENHANCEMENT\": \"FALSE\",\n",
      " \"FILTRATION\": \"FALSE\",\n",
      " \"TRAIN_TYPE\": \"FINETUNE\",\n",
      " \"NMS_THRESHOLD\": 0.9,\n",
      " \"PRED_CONFIDENCE_THRESHOLD\": 0.6,\n",
      " \"ENSEMBLE_BOX_OVERLAP_THRESHOLD\": 0.5,\n",
      " \"ENSEMBLE_BOX_BETA\": 0.4,\n",
      " \"RPN_MODEL_PATH\": \"rpn/checkpoints/1692043128/rpn_model_1.09.pth\",\n",
      " \"SAM_MODEL_PATH\": \"sam/checkpoint/sam_vit_l_0b3195.pth\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Create a folder with unix timestamp\n",
    "root_path = os.getcwd() + '/results/' + str(int(time.time())) + '/'\n",
    "os.mkdir(root_path)\n",
    "\n",
    "with open('eval_config.json', 'r') as f:\n",
    "    eval_config = json.load(f)\n",
    "\n",
    "\n",
    "print(\"Evaluation Configuration\")\n",
    "print(json.dumps(eval_config, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the device and load the dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "dataset_test = PlanetscopeDataset(eval_config['DATASET_PATH'], get_transform(image_enhancement=eval_config['IMAGE_ENHANCEMENT']))\n",
    "# dataset2_test = PlanetscopeDataset(eval_config['DATASET2_PATH'], get_transform(image_enhancement=eval_config['IMAGE_ENHANCEMENT']))\n",
    "\n",
    "# dataset_test = ConcatDataset([dataset1_test, dataset2_test])\n",
    "\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset_test)).tolist()\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-int(len(indices)*0.2):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the proper model to be used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_config['MODEL'] == 'SAT-SAM':\n",
    "    rpn_model = RPN_Model(eval_config['RPN_MODEL_PATH'], 2, device, eval_config['TRAIN_TYPE'])\n",
    "    sam_model = SAM_Model(eval_config['SAM_MODEL_PATH'], 'large', device)\n",
    "elif eval_config['MODEL'] == 'SAM':\n",
    "    vanilla_sam_model = pipeline(\"mask-generation\", model=\"facebook/sam-vit-large\", device=device)\n",
    "elif eval_config['MODEL'] == 'MASKRCNN':\n",
    "    maskrcnn_model = RPN_Model(eval_config['RPN_MODEL_PATH'], 2, device, eval_config['TRAIN_TYPE']) #Load the Pre-Trained MaskRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(predicted, target):\n",
    "    correct_pixels = np.sum(predicted == target)\n",
    "    total_pixels = predicted.shape[0] * predicted.shape[1]\n",
    "    accuracy = correct_pixels / total_pixels\n",
    "    return accuracy\n",
    "\n",
    "def f1_score(predicted, target):\n",
    "    true_positive = np.sum(np.logical_and(predicted == 1, target == 1))\n",
    "    false_positive = np.sum(np.logical_and(predicted == 1, target == 0))\n",
    "    false_negative = np.sum(np.logical_and(predicted == 0, target == 1))\n",
    "    \n",
    "    precision = true_positive / (true_positive + false_positive + 1e-8)\n",
    "    recall = true_positive / (true_positive + false_negative + 1e-8)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1\n",
    "\n",
    "def mean_iou(predicted, target):\n",
    "    intersection = np.logical_and(predicted, target)\n",
    "    union = np.logical_or(predicted, target)\n",
    "    \n",
    "    intersection_area = np.sum(intersection)\n",
    "    union_area = np.sum(union)\n",
    "    \n",
    "    iou = intersection_area / (union_area + 1e-8)\n",
    "    return iou\n",
    "\n",
    "def precision_at_iou_threshold(predicted, target, iou_threshold):\n",
    "    true_positive = np.sum(np.logical_and(predicted == 1, target == 1))\n",
    "    false_positive = np.sum(np.logical_and(predicted == 1, target == 0))\n",
    "    \n",
    "    iou = true_positive / (true_positive + false_positive + 1e-8)\n",
    "    \n",
    "    precision = 0.0\n",
    "    if iou >= iou_threshold:\n",
    "        precision = iou\n",
    "        \n",
    "    return precision\n",
    "\n",
    "def collate_mask(masks, img_size):\n",
    "    cumulative_mask = np.zeros(img_size, dtype=np.uint8)\n",
    "    \n",
    "    for mask in masks:\n",
    "        cumulative_mask[mask > 0] = 1\n",
    "    \n",
    "    return cumulative_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM\n",
      "Image Id:  42\n",
      "Pixel Accuracy:  0.7205088089923469\n",
      "F1 Score:  0.4335268829950461\n",
      "mIoU:  0.27675348117582815\n",
      "SAM\n",
      "Image Id:  14\n",
      "Pixel Accuracy:  0.49037388392857145\n",
      "F1 Score:  0.2963401160787921\n",
      "mIoU:  0.1739432411041516\n",
      "SAM\n",
      "Image Id:  30\n",
      "Pixel Accuracy:  0.5633320711096939\n",
      "F1 Score:  0.5607077469307503\n",
      "mIoU:  0.3895718554324009\n",
      "SAM\n",
      "Error in image:  18\n",
      "SAM\n",
      "Image Id:  67\n",
      "Pixel Accuracy:  0.21432557397959184\n",
      "F1 Score:  0.326913552211735\n",
      "mIoU:  0.19539549550467922\n",
      "SAM\n",
      "Image Id:  71\n",
      "Pixel Accuracy:  0.5151815609056123\n",
      "F1 Score:  0.14296660819850787\n",
      "mIoU:  0.07698655865528908\n",
      "SAM\n",
      "Image Id:  68\n",
      "Pixel Accuracy:  0.35691366390306123\n",
      "F1 Score:  0.23483240156174803\n",
      "mIoU:  0.1330368897605972\n",
      "SAM\n",
      "Image Id:  27\n",
      "Pixel Accuracy:  0.6736138791454082\n",
      "F1 Score:  0.0858765537497664\n",
      "mIoU:  0.04486469147322337\n",
      "SAM\n",
      "Image Id:  60\n",
      "Pixel Accuracy:  0.20720065369897958\n",
      "F1 Score:  0.2905133026914527\n",
      "mIoU:  0.16994183468529853\n",
      "SAM\n",
      "Image Id:  51\n",
      "Pixel Accuracy:  0.3774264588647959\n",
      "F1 Score:  0.26044496072963697\n",
      "mIoU:  0.14971930182707974\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  29\n",
      "Pixel Accuracy:  0.29853914221938777\n",
      "F1 Score:  0.4578105347845886\n",
      "mIoU:  0.2968575195780577\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  56\n",
      "Pixel Accuracy:  0.35316685267857145\n",
      "F1 Score:  0.03879699592288187\n",
      "mIoU:  0.019782244303165174\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image:  93\n",
      "SAM\n",
      "Image Id:  47\n",
      "Pixel Accuracy:  0.4407286352040816\n",
      "F1 Score:  0.6117920440058021\n",
      "mIoU:  0.4407063419300613\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  97\n",
      "Pixel Accuracy:  0.652946627869898\n",
      "F1 Score:  0.30645305522666993\n",
      "mIoU:  0.18095338883399406\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  94\n",
      "Pixel Accuracy:  0.7407176737882653\n",
      "F1 Score:  0.32394932926063064\n",
      "mIoU:  0.19328134931089755\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  86\n",
      "Pixel Accuracy:  0.6870167012117347\n",
      "F1 Score:  0.18850521086412286\n",
      "mIoU:  0.10406058790807639\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  87\n",
      "Pixel Accuracy:  0.33530970982142855\n",
      "F1 Score:  0.16567018262771485\n",
      "mIoU:  0.09031646562245806\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  65\n",
      "Pixel Accuracy:  0.319271165497449\n",
      "F1 Score:  0.4836018755824528\n",
      "mIoU:  0.31891485002416164\n",
      "SAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Id:  53\n",
      "Pixel Accuracy:  0.4210628587372449\n",
      "F1 Score:  0.21990076750506538\n",
      "mIoU:  0.12353287270312557\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['parcel_id', 'parcel_path', 'gt_mask_ct', 'pred_mask_ct', 'pixel_acc', 'F1_score', 'mIoU'])\n",
    "    \n",
    "for i, (id, sam_image, rpn_image, target, ensemble, path)  in enumerate(dataset_test): \n",
    "    try:\n",
    "        if eval_config['MODEL'] == 'SAT-SAM':\n",
    "            rpn_image = rpn_image.squeeze(0).to(device)  \n",
    "            predictions = rpn_model.predict(rpn_image)\n",
    "            predictions = rpn_model.postprocess(predictions, nms_threshold=eval_config['NMS_THRESHOLD'], score_threshold=eval_config['PRED_CONFIDENCE_THRESHOLD'])\n",
    "            \n",
    "            if predictions['boxes'].shape[0] == 0:\n",
    "                print(\"No boxes detected, generating uniform boxes\")\n",
    "                bboxes = generate_uniform_spaced_bounding_boxes(sam_image.size[0], sam_image.size[1], int(sam_image.size[0]*0.25))\n",
    "                if eval_config['FILTRATION'] == 'TRUE':\n",
    "                    filtered_boxes = filter_boxes(bboxes, ensemble, eval_config['ENSEMBLE_BOX_OVERLAP_THRESHOLD'])\n",
    "                    low_res_masks, iou_predictions = sam_model.predict(sam_image, filtered_boxes)\n",
    "                else:\n",
    "                    low_res_masks, iou_predictions = sam_model.predict(sam_image, bboxes)\n",
    "            else:\n",
    "                if eval_config['FILTRATION'] == 'TRUE':\n",
    "                    filtered_predictions = filter_boxes_predictions(predictions, ensemble, eval_config['ENSEMBLE_BOX_BETA'], eval_config['ENSEMBLE_BOX_OVERLAP_THRESHOLD'])\n",
    "                    low_res_masks, iou_predictions = sam_model.predict(sam_image, filtered_predictions)\n",
    "                else:\n",
    "                    low_res_masks, iou_predictions = sam_model.predict(sam_image, predictions['boxes'])\n",
    "            \n",
    "            high_res_masks = sam_model.postprocess(low_res_masks, tuple(sam_image.size))\n",
    "            pred_masks = high_res_masks.squeeze().cpu().numpy()\n",
    "            \n",
    "        elif eval_config['MODEL'] == 'SAM':\n",
    "            print('SAM')\n",
    "            outputs = vanilla_sam_model(sam_image, points_per_batch=32)\n",
    "            if eval_config['FILTRATION'] == 'TRUE':\n",
    "                pred_masks = filter_masks(outputs['masks'], ensemble, eval_config['ENSEMBLE_BOX_OVERLAP_THRESHOLD'])\n",
    "            else:\n",
    "                pred_masks = outputs[\"masks\"]\n",
    "\n",
    "        elif eval_config['MODEL'] == 'MASKRCNN':\n",
    "            print('MASKRCNN')\n",
    "            rpn_image = rpn_image.squeeze(0).to(device)\n",
    "            predictions = maskrcnn_model.predict(rpn_image)\n",
    "            predictions = maskrcnn_model.postprocess(predictions, nms_threshold=eval_config['NMS_THRESHOLD'], score_threshold=eval_config['PRED_CONFIDENCE_THRESHOLD'])\n",
    "            if eval_config['FILTRATION'] == 'TRUE':\n",
    "                pred_masks = filter_masks(np.squeeze(np.array(predictions['masks'])), ensemble, eval_config['ENSEMBLE_BOX_OVERLAP_THRESHOLD'])\n",
    "            else:\n",
    "                pred_masks = predictions['masks'].squeeze()\n",
    "            pred_masks = np.array(pred_masks) > 0.5\n",
    "\n",
    "\n",
    "\n",
    "        # Stack the target masks to get a single mask\n",
    "        pred_masks = collate_mask(pred_masks, sam_image.size)\n",
    "        target_masks = collate_mask(target['masks'], sam_image.size)\n",
    "\n",
    "        pix_acc = pixel_accuracy(pred_masks, target_masks)\n",
    "        f1_sc = f1_score(pred_masks, target_masks) \n",
    "        mIoU = mean_iou(pred_masks, target_masks)\n",
    "        # precision_95 = precision_at_iou_threshold(pred_masks, target_masks, 0.95)\n",
    "\n",
    "        print(\"Image Id: \", id)\n",
    "        print(\"Pixel Accuracy: \", pix_acc)\n",
    "        print(\"F1 Score: \", f1_sc)\n",
    "        print(\"mIoU: \", mIoU)\n",
    "        # print(\"Precision @ 0.95: \", precision_95)\n",
    "\n",
    "        results.loc[i] = [id, path, len(target['masks']), len(pred_masks), pix_acc, f1_sc, mIoU]\n",
    "    except:\n",
    "        print(\"Error in image: \", id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config['MEAN_IOU'] = results['mIoU'].mean()\n",
    "eval_config['MEAN_PIXEL_ACCURACY'] = results['pixel_acc'].mean()\n",
    "eval_config['MEAN_F1_SCORE'] = results['F1_score'].mean()\n",
    "# eval_config['MEAN_PRECISION@0.95'] = results['precision@0.95'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Configuration saved to /home/aghosh57/Kerner-Lab/SAT-SAM/results/1692694771/train_config.json\n"
     ]
    }
   ],
   "source": [
    "results.to_csv(root_path + 'results', index=False)\n",
    "\n",
    "# save model and configuration\n",
    "with open(root_path + 'eval_config.json', 'w') as f:\n",
    "    json.dump(eval_config, f, indent=1)\n",
    "    f.close()\n",
    "print(\"Evaluation Configuration saved to \" + root_path + 'train_config.json') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
