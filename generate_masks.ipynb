{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports are Necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aghosh57/.conda/envs/dl4cv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rpn.build_rpn import RPN_Model\n",
    "from sam.build_sam import SAM_Model\n",
    "from transformers import pipeline\n",
    "\n",
    "from data_builder.build_dataset import PlanetscopeDataset\n",
    "\n",
    "import json\n",
    "\n",
    "from eval_utils import filter_boxes, calculate_iou, calculate_precision_recall, filter_masks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "from rpn import _transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(image_enhancement=\"FALSE\"):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    if image_enhancement == \"TRUE\":\n",
    "        transforms.append(T.ContrastBasedAdaptiveGammaCorrection())\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usual Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask Gen Configuration\n",
      "{\n",
      " \"DATASET_PATH\": \"/scratch/aghosh57/SAT-SAM(Dataset)/ps_rwanda/all_dataset/\",\n",
      " \"REGION\": \"FRANCE\",\n",
      " \"MODEL\": \"MASKRCNN\",\n",
      " \"IMAGE_ENHANCEMENT\": \"FALSE\",\n",
      " \"TRAIN_TYPE\": \"FINETUNE\",\n",
      " \"NMS_THRESHOLD\": 0.9,\n",
      " \"PRED_CONFIDENCE_THRESHOLD\": 0.6,\n",
      " \"ENSEMBLE_BOX_OVERLAP_THRESHOLD\": 0.5,\n",
      " \"ENSEMBLE_BOX_BETA\": 0.3,\n",
      " \"RPN_MODEL_PATH\": \"rpn/checkpoints/1692042915/rpn_model_1.07.pth\",\n",
      " \"SAM_MODEL_PATH\": \"sam/checkpoint/sam_vit_l_0b3195.pth\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('gen_masks_config.json', 'r') as f:\n",
    "    eval_config = json.load(f)\n",
    "\n",
    "print(\"Mask Gen Configuration\")\n",
    "print(json.dumps(eval_config, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dataset = PlanetscopeDataset(eval_config['DATASET_PATH'], get_transform(image_enhancement=eval_config['IMAGE_ENHANCEMENT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_config['MODEL'] == 'SAT-SAM':\n",
    "    rpn_model = RPN_Model(eval_config['RPN_MODEL_PATH'], 2, device, eval_config['TRAIN_TYPE'])\n",
    "    sam_model = SAM_Model(eval_config['SAM_MODEL_PATH'], 'large', device)\n",
    "elif eval_config['MODEL'] == 'SAM':\n",
    "    vanilla_sam_model = pipeline(\"mask-generation\", model=\"facebook/sam-vit-large\", device=device)\n",
    "elif eval_config['MODEL'] == 'MASKRCNN':\n",
    "    maskrcnn_model = RPN_Model(eval_config['RPN_MODEL_PATH'], 2, device, eval_config['TRAIN_TYPE']) #Load the Pre-Trained MaskRCNN model\n",
    "    # maskrcnn_model = RPN_Model(None, 2, device)   #Load the Vanilla MaskRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, rgb_image, rpn_image, target, ensemble, path = dataset[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASKRCNN\n"
     ]
    }
   ],
   "source": [
    "if eval_config['MODEL'] == 'SAT-SAM':\n",
    "    print('SAT-SAM')\n",
    "    rpn_image = rpn_image.squeeze(0).to(device)  \n",
    "    predictions = rpn_model.predict(rpn_image)\n",
    "    predictions = rpn_model.postprocess(predictions, nms_threshold=eval_config['NMS_THRESHOLD'], score_threshold=eval_config['PRED_CONFIDENCE_THRESHOLD'])\n",
    "\n",
    "    filtered_predictions = filter_boxes(predictions, ensemble, eval_config['ENSEMBLE_BOX_BETA'], eval_config['ENSEMBLE_BOX_OVERLAP_THRESHOLD'])\n",
    "\n",
    "    low_res_masks, iou_predictions = sam_model.predict(rgb_image, filtered_predictions)\n",
    "    high_res_masks = sam_model.postprocess(low_res_masks, tuple(rgb_image.size))\n",
    "    pred_masks = high_res_masks.squeeze().cpu().numpy()\n",
    "\n",
    "elif eval_config['MODEL'] == 'SAM':\n",
    "    print('SAM')\n",
    "    outputs = vanilla_sam_model(rgb_image, points_per_batch=32)\n",
    "    # pred_masks = outputs[\"masks\"]\n",
    "    pred_masks = filter_masks(outputs, ensemble, eval_config['ENSEMBLE_BOX_OVERLAP_THRESHOLD'])\n",
    "\n",
    "elif eval_config['MODEL'] == 'MASKRCNN':\n",
    "    print('MASKRCNN')\n",
    "    rpn_image = rpn_image.squeeze(0).to(device)\n",
    "    predictions = maskrcnn_model.predict(rpn_image)\n",
    "    predictions = maskrcnn_model.postprocess(predictions, nms_threshold=eval_config['NMS_THRESHOLD'], score_threshold=eval_config['PRED_CONFIDENCE_THRESHOLD'])\n",
    "    pred_masks = predictions['masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0078, 0.0104, 0.0130,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masks = np.squeeze(np.array(pred_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_masks[\u001b[39m'\u001b[39;49m\u001b[39mmasks\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "pred_masks['masks']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Predicted & Ground Truth Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(12, 5))\n",
    "\n",
    "ax[0].imshow(rgb_image)\n",
    "ax[0].set_xlabel('Ground Truth')\n",
    "\n",
    "for i in range (len(target['boxes'])):\n",
    "    xmin = target['boxes'][i][0]\n",
    "    \n",
    "    ymin = target['boxes'][i][1]\n",
    "    xmax = target['boxes'][i][2]\n",
    "    ymax = target['boxes'][i][3]\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[0].add_patch(rect)\n",
    "\n",
    "ax[1].imshow(rgb_image)\n",
    "ax[1].set_xlabel('Predicted')\n",
    "\n",
    "for i in range (len(predictions['boxes'])):\n",
    "    xmin = predictions['boxes'][i][0]\n",
    "    ymin = predictions['boxes'][i][1]\n",
    "    xmax = predictions['boxes'][i][2]\n",
    "    ymax = predictions['boxes'][i][3]\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[1].add_patch(rect)\n",
    "\n",
    "ax[2].imshow(rgb_image)\n",
    "ax[2].set_xlabel('Filtered Predicted')\n",
    "\n",
    "for i in range (len(filtered_predictions)):\n",
    "    xmin = filtered_predictions[i][0]\n",
    "    ymin = filtered_predictions[i][1]\n",
    "    xmax = filtered_predictions[i][2]\n",
    "    ymax = filtered_predictions[i][3]\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[2].add_patch(rect)\n",
    "\n",
    "\n",
    "ax[3].imshow(ensemble)\n",
    "ax[3].set_xlabel('Filtered Predicted')\n",
    "\n",
    "for i in range (len(filtered_predictions)):\n",
    "    xmin = filtered_predictions[i][0]\n",
    "    ymin = filtered_predictions[i][1]\n",
    "    xmax = filtered_predictions[i][2]\n",
    "    ymax = filtered_predictions[i][3]\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[3].add_patch(rect)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment Anything Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IoU\n",
    "iou_score = calculate_iou(target_masks=np.array(target['masks']), predicted_masks=np.array(pred_masks))\n",
    "print(\"Average IoU:\", iou_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Predicted & Ground Truth Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_high_mask = np.zeros(tuple(rgb_image.size), dtype=np.uint8)\n",
    "\n",
    "delta_pred_mask = 255 // len(pred_masks)\n",
    "\n",
    "for i, mask in enumerate(pred_masks):\n",
    "    cumulative_high_mask[mask > 0] = (i + 1)*delta_pred_mask\n",
    "\n",
    "\n",
    "cumulative_gt_mask = np.zeros(tuple(rgb_image.size), dtype=np.uint8)\n",
    "delta = 100 // len(target['masks'])\n",
    "\n",
    "for i, mask in enumerate(target['masks']):\n",
    "    cumulative_gt_mask[mask > 0] = (i + 1)*delta\n",
    "\n",
    "\n",
    "#Plot both masks\n",
    "fig, ax = plt.subplots(1,3, figsize=(10,5))\n",
    "ax[0].imshow(cumulative_gt_mask, cmap='jet')\n",
    "ax[0].set_xlabel('Ground Truth')\n",
    "\n",
    "ax[1].imshow(cumulative_high_mask, cmap='jet')\n",
    "ax[1].set_xlabel('Predicted (Filtered)')\n",
    "\n",
    "ax[2].imshow(ensemble)\n",
    "ax[2].set_xlabel('Ensemble')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
